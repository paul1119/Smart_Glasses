import cv2import timeimport pytesseract# import torchimport easyocr#from ultralytics import YOLO#model = YOLO("best_text_area.pt")cap = cv2.VideoCapture(0)while True:    ret, frame = cap.read()    if not ret:        break    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)    gray = cv2.GaussianBlur(gray, (3, 3), 0)    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)       ocr_config = '--psm 3 --oem 1'    # resize if text is small    thresh = cv2.resize(thresh, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)    start_time = time.time()    text = pytesseract.image_to_string(thresh, config=ocr_config, lang='eng')     # results = reader.readtext(gray)    end_time = time.time()    # Print results    print("üîç OCR Results:\n")    print(text)    # for bbox, text, confidence in results:    #     print(f"Text: '{text}' | Confidence: {confidence:.2f}")        elapsed_time = end_time - start_time    print(f"\n Inference Time: {elapsed_time:.3f} seconds")    # Get predictions (xyxy format)    # labels = [results        # cv2.imshow("camera image", frame)    # if cv2.waitKey(1) & 0xFF == ord('q'):    #     breakcap.release()# cv2.destroyAllWindows()